{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions, Explanations and Functions Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation:\n",
    "* Correlation Matrix = $\\mathbf{R}$\n",
    "* Provides the direction and strength of a relationship.\n",
    "* the correlation result will always be between -1 and +1 and its scale is independent of the scale of the variables themselves.\n",
    "* Correlation is standardized (think z-score) It is the standardized version of the correlatin matrix. This means you would want to use this if your variables are being measured using different scales.\n",
    "* Correlation is only applicable to LINEAR relationships. There are many other tyes of relationships that can exist between two variables.\n",
    "* Correlation is NOT Causation.\n",
    "* Correlation strength does not necessarily mena the correlation is statistically significant; related to sample size.\n",
    "* Interpretation: Positive relationship is near +1, negative relationship is near -1, no correlation it will be near 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance:\n",
    "* [Definition](http://mathworld.wolfram.com/Covariance.html) - Covariance provides a measure of the strength of the correlation between two or more sets of random variates. Other sources say it will just so you the direction it will not show you the strength.\n",
    "* Lecture Slides - Variance-Covariance Matrix, S - Measures variability in the variables\n",
    "* Covariance is one of a family of statistical measures used to analyze the linear relationship between two variables. It is a descriptive measure of the linear association between two variables.\n",
    "* Covariance result has no upper or lower bound and its size is dependent on the scale of the variables.\n",
    "* Covariance is not standardized.\n",
    "\n",
    "## Covariance Matrix:\n",
    "* Variance-covariance matrix = $\\mathbf{S}$\n",
    "* Variance-covariance matrix aka the covariance matrix or the dispersion matrix.\n",
    "* [Covariance Matrix](https://www.youtube.com/watch?v=locZabK4Als)\n",
    "* Interpretation: A positive value indicates a direct or increasing linear relationship, A negative value indicates a decreasing relationship. Covariance at or around zero indicates that there is not a linear relationship between the two. Covariance does not tell us anything about the strength of the relationship just the direction of the relationship. To find the strength of the relationship you will want to look at correlation.\n",
    "* The diagonal of a covariance matrix provides the variance of each individual variable; covariance with itself.\n",
    "* The off-diagonal entries in the matrix provide the covariance between each variable pair.\n",
    "* Remember that the standard deviation is simply the square root of the variance so that can be calculated as well.\n",
    "* [Explanation](https://datascienceplus.com/understanding-the-covariance-matrix/) of the covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues\n",
    "* For a square matrix $\\mathbf{A}$ and a non-zero vector $\\mathbf{x}$ if $\\mathbf{Ax = \\lambda x}$ for some constant $\\lambda{}$ then we say that $\\lambda$ is an eigenvalue of $\\mathbf{A}$ and that $\\mathbf{x}$ is an eigenvecotr of $\\mathbf{A}$ corresponding to the eigenvalue of $\\lambda$.\n",
    "* The scalar that is used to transform (stretch) an Eigenvector\n",
    "* The Eigenvalue divided by the total variance will give you the proportion of the variability explained by that vector?  ASK ABOUT THAT INTERPRETATION!!!!!\n",
    "* The total variance comes from adding up all the diagonal values in the covariance matrix.\n",
    "* At least for the correlation matrix you can find out the proportion of variability that is explained by a variable through its eigenvalue. By adding up all of the eigenvalues and then dividing the eigenvalue by the sum of all eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvectors\n",
    "* It s a vector that is scaled up by a transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrix\n",
    "* [Description](http://mathworld.wolfram.com/IdentityMatrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal Matrix\n",
    "* [Definition of Orthogonal](http://mathworld.wolfram.com/Orthogonal.html)\n",
    "* [Description of Orthogonal Matrix](http://mathworld.wolfram.com/OrthogonalMatrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Eiganvalues & Eiganvectors](https://medium.com/fintechexplained/what-are-eigenvalues-and-eigenvectors-a-must-know-concept-for-machine-learning-80d0fd330e47)\n",
    "* [Eigenvectos & Eigenvalues Video](https://www.youtube.com/watch?v=PFDu9oVAE-g)\n",
    "* [Simple Statistics](https://www.youtube.com/watch?v=xGbpuFNR1ME&list=PLIeGtxpvyG-JMH5fGDWhtniyET88Mexcw&index=5)\n",
    "* [Symbols, Meaning, Latex](https://en.wikipedia.org/wiki/List_of_mathematical_symbols)\n",
    "* [PCA Eigenvectors and Eigenvaleus](https://towardsdatascience.com/pca-eigenvectors-and-eigenvalues-1f968bc6777a)\n",
    "* [PCA Analysis: Minitab](https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/principal-components/interpret-the-results/key-results/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href=\"http://mathworld.wolfram.com/Covariance.html\">Wolfram</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "  <li>Coffee</li>\n",
    "  <li>Tea</li>\n",
    "  <li>Milk</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
